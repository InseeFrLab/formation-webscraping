{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {},
      "source": [
        "---\n",
        "title: Formation au web scraping \n",
        "subtitle: |\n",
        "  **[Rabat - Coopération internationale]{.orange}**\n",
        "author:\n",
        "  - name : \"[[Antoine Palazzolo, INSEE](https://github.com/antoine-palazz/)]{.orange}\"\n",
        "# uncomment for French presentations:\n",
        "lang: fr-FR\n",
        "date: 12/01/2022\n",
        "date-format: long\n",
        "slide-number: true\n",
        "# for blind readers:\n",
        "slide-tone: false\n",
        "chalkboard: # press the B key to toggle chalkboard\n",
        "  theme: whiteboard\n",
        "# uncomment to use the multiplex mode:\n",
        "# multiplex: true\n",
        "format:\n",
        "  onyxia-revealjs:\n",
        "    output-file: index.html\n",
        "controls: true\n",
        "css: custom.css\n",
        "from: markdown+emoji\n",
        "ascii: true\n",
        "---"
      ],
      "id": "d8f96106"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sommaire {#index}\n",
        "\n",
        "<br>\n",
        "\n",
        "[I. Introduction au web scraping](#index_01)\n",
        "\n",
        "[II. Mise en pratique](#index_02)\n",
        "\n",
        "[III. Divers cas d'usage](#index_03)\n",
        "\n",
        "[IV. D'autres organisations adeptes de scraping](#index_04)\n",
        "\n",
        "[V. Conclusion](#index_05)\n",
        "\n",
        "\n",
        "# I. Introduction au web scraping {#index_01}\n",
        "\n",
        "# I. Sommaire\n",
        "\n",
        "<br>\n",
        "\n",
        "[Présentation générale et usages courants](#01_01)\n",
        "\n",
        "[Risques juridiques et scraping éthique](#01_02)\n",
        "\n",
        "[Rappels sur _HTML_](#01_03)\n",
        "\n",
        "\n",
        "# Présentation générale et usages courants {#01_01}\n",
        "\n",
        "## Qu'est-ce que le [web scraping](https://librarycarpentry.org/lc-webscraping/01-introduction/index.html) ?\n",
        "\n",
        "<br>\n",
        "\n",
        "- Le [web scraping](https://fr.wikipedia.org/wiki/Web_scraping) désigne un ensemble de techniques d'__extraction de contenu__ sur des sites internet.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Le terme fait généralement référence à l'usage de [bots](https://en.wikipedia.org/wiki/Internet_bot) pour collecter ces contenus automatiquement.\n",
        "\n",
        "\n",
        "## Exemples introductifs\n",
        "\n",
        "<br>\n",
        "\n",
        "- On souhaite accéder à la [liste des présidents des États-Unis](https://fr.wikipedia.org/wiki/Liste_des_pr%C3%A9sidents_des_%C3%89tats-Unis) et réunir les dates de mandat dans un `Excel`.\n",
        "\n",
        ". . .\n",
        "\n",
        "- On souhaite télécharger le [classement QS 2023 des universités](https://www.universityrankings.ch/results/QS/2023) et filtrer les universités italiennes.\n",
        "\n",
        ". . .\n",
        "\n",
        "\n",
        "- On souhaite accéder à un [répertoire d'expressions idiomatiques](https://fr.wiktionary.org/wiki/Annexe:Expressions_en_fran%C3%A7ais) et trouver toutes celles contenant le mot \"nez\".\n",
        "\n",
        "\n",
        "## `Web scraping`, `web crawling`, `screen scraping`, quelles différences ? {.smaller}\n",
        "\n",
        "<br>\n",
        "\n",
        "- Le [web scraping](https://en.wikipedia.org/wiki/Web_scraping) se réfère à l'extraction des données, ou captation d'informations, sur une ou plusieurs pages web.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Le [web crawling](https://en.wikipedia.org/wiki/Web_crawler), ou [spidering]{.blue2} correspond à la recherche (ou la navigation parmi) de nouveaux URLs sur Internet ou sur un site spécifique.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Quant au [screen scraping](https://en.wikipedia.org/wiki/Data_scraping#Screen_scraping), proche du web scraping, il consiste plutôt à extraire le contenu visuel d'un site apparaissant à l'écran, comme des images.\n",
        "\n",
        ". . .\n",
        "\n",
        "::: {.callout-note}\n",
        "`Web scraping` et `web crawling` peuvent aller ensemble : \n",
        "\n",
        "- On utile d'abord un crawler pour récupérer tous les urls d'un site ...\n",
        "- ... Puis on scrape chacune des pages les unes après les autres\n",
        ":::\n",
        "\n",
        "## Cas d'usage pratiques\n",
        "\n",
        "#### Études de marché et intelligence économique\n",
        "\n",
        "- Faire un suivi des prix sur des site de ventes (possiblement concurrents) en les scrapant régulièrement\n",
        "    + On peut alors parler de [price scraping](https://www.minderest.com/fr/blog/qu-est-ce-que-price-scraping)\n",
        " \n",
        ". . . \n",
        "\n",
        "- Glaner des informations sur les sites d'entreprises concurrentes\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Exemple\n",
        "\n",
        "Dans les répertoires d'expressions idiomatiques, il est facile de \"dérober\" les contenus les uns des autres ([Expressio](https://www.expressio.fr/toutes-les-expressions), [Expressions Françaises](https://www.expressions-francaises.fr/), [L'internaute](https://www.linternaute.fr/expression/)...)\n",
        ":::\n",
        "\n",
        "\n",
        "## Cas d'usage pratiques\n",
        "\n",
        "#### Analyses de sentiment et génération de _leads_\n",
        "\n",
        "<br>\n",
        "\n",
        "- Récupérer les commentaires d'un produit ou d'une entreprise sur un site tiers afin d'analyser les retours obtenus et faire du _sentiment analysis_\n",
        "    + Un [papier de recherche](https://doi.org/10.1007/978-3-030-16660-1_66) sur le sujet\n",
        "\n",
        ". . .\n",
        "\n",
        "- Obtenir une liste de clients potentiels ou répondant à des critères spécifiques \n",
        "    + À partir de sites comme les [Pages Jaunes](https://www.pagesjaunes.fr/pagesblanches) ou [Google Maps](https://www.google.com/business/) pour les entreprises\n",
        "\n",
        "\n",
        "## Cas d'usage pratiques\n",
        "\n",
        "#### Obtenir des données pour alimenter des modèles de ML\n",
        "\n",
        "- Regrouper divers indicateurs et séries temporelles via les [Google Trends](https://trends.google.fr/trends/?geo=FR) pour améliorer les performances de modèles de prédiction\n",
        "    + En phase expérimentale à l'INSEE, par exemple pour des problématiques de [nowcasting](https://statistics-awards.eu/competitions/3)\n",
        "\n",
        ". . .\n",
        "\n",
        "- Surveiller les valeurs de stocks boursiers et mouvements de marché sur [Yahoo Finance](https://fr.finance.yahoo.com/) et les inclure dans des modèles\n",
        "    + En l'occurrence, `Yahoo Finance` offre aussi une [API](https://algotrading101.com/learn/yahoo-finance-api-guide/) pour l'extraction de données\n",
        "\n",
        "\n",
        "## Cas d'usage pratiques {.smaller}\n",
        "\n",
        "#### Dans des domaines spécifiques\n",
        "\n",
        "<br>\n",
        "\n",
        "- Dans le domaine immobilier, de nombreuses agences utilisent le scraping pour alimenter leur propre base de biens à vendre ou à louer.\n",
        "    + On peut aussi trouver de nombreux agrégateurs d'annonces en ligne.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Dans le domaine aérien, nombreux sont les comparateurs en ligne qui ont recours au scraping pour présenter des offres de trajets issues de plusieurs compagnies.\n",
        "    + Ex : [kiwi.com](https://www.kiwi.com/fr/), [lastminute.com](https://www.fr.lastminute.com/)...\n",
        "    + Ce n'est d'ailleurs pas le cas que dans le domaine du transport (ex: hébergement touristique).\n",
        "\n",
        ". . .\n",
        "\n",
        "- Dans le domaine des paris sportifs, il est courant de scraper les sites de statistiques sportives afin d'adapter l'offre des paris.\n",
        "\n",
        "\n",
        "## Cas d'usage pratiques\n",
        "\n",
        "#### Dans le domaine de la recherche\n",
        "\n",
        "- Pour des chercheurs, le web scraping peut représenter une importante source de données, et ce dans des domaines très variés.\n",
        "\n",
        "    + Un exemple [ici](https://doi.org/10.1038/s41597-022-01369-4) avec une équipe ayant scrapé [Wikipedia](https://fr.wikipedia.org/wiki/Wikip%C3%A9dia:Accueil_principal) pour compléter des données extraites de [Wikidata](https://www.wikidata.org/wiki/Wikidata:Main_Page), afin d'établir une base de données de tous les individus ayant leur propre page, pour ensuite établir des statistiques par période, par domaine ou par sexe.\n",
        "\n",
        "    + Un [code](https://data.sciencespo.fr/dataset.xhtml?persistentId=doi:10.21410/7E4/YLG6YR) en open source\n",
        "\n",
        "\n",
        "## Cas d'usage pour un INS\n",
        "\n",
        "- Scraper divers sites de ventes afin d'obtenir des données de prix pour le __calcul de l'indice des prix à la consommation__ (`IPC`)\n",
        "\n",
        ". . .\n",
        "\n",
        "- Compléter des données de statistiques d'entreprises avec des informations disponibles en ligne\n",
        "\n",
        ". . .\n",
        "\n",
        "- Minimiser la charge de réponse lors des enquêtes en favorisant le scraping\n",
        "\n",
        ". . .\n",
        "\n",
        "- Construire des bases de sondages, par exemple en scrapant les annuaires d'enseigne\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Risques juridiques et scraping éthique {#01_02}\n",
        "\n",
        "## Le web scraping, est-ce légal ?\n",
        "\n",
        "<br>\n",
        "\n",
        "- Le web scraping en lui-même n'est pas une pratique illégale ...\n",
        "    - ... Mais l'utilisation faite des données scrapées peut être soumise à réglementation.\n",
        "    - Ces règles dépendent alors du pays dans lequel on se trouve ainsi que des données scrapées. \n",
        "\n",
        ". . .\n",
        "\n",
        "::: {.callout-important}\n",
        "## Attention\n",
        "\n",
        "Diffuser ou commercialiser des données scrapées ou un quelconque travail réutilisant ces données n'est pas sans conséquence.\n",
        ":::\n",
        "\n",
        "\n",
        "## Une frontière floue\n",
        "\n",
        "- Les législations spécifiques au web scraping sont peu nombreuses et différentes d'un pays à l'autre.\n",
        "\n",
        ". . .\n",
        "\n",
        "- En revanche, la réutilisation des données est encadrée.\n",
        "    + Par exemple par le code de la propriété intellectuelle ou par le `RGPD`.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Les [cas portés en justice](https://devm.io/law-net-culture/data-scraping-cases-165385) ont des dénouements parfois différents les uns les autres, notamment d'un pays à l'autre, montrant bien qu'il s'agit là d'une zone parfois grise.\n",
        "\n",
        "\n",
        "## Une pratique pourtant très répandue\n",
        "\n",
        "<br>\n",
        "\n",
        "- Les cas d'usage, y compris dans de grandes entreprises, sont très nombreux.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Les articles discutant de web scraping et de leur légalité sont tout aussi proliférants, mais pas toujours d'accord les uns avec les autres.\n",
        "    - Quelques ressources : [Imperva](https://www.imperva.com/blog/is-web-scraping-illegal/), [Islean Consulting](https://islean-consulting.fr/fr/transformation-digitale/scraping-pages-web-legal/), [TechCrunch](https://techcrunch.com/2022/04/18/web-scraping-legal-court/)...\n",
        "\n",
        "\n",
        "## Les principales réglementations autour du web scraping {.smaller}\n",
        "\n",
        "#### En France\n",
        "\n",
        "- [L'article L.\\ 342-1 du code de la propriété intellectuelle](https://www.legifrance.gouv.fr/codes/article_lc/LEGIARTI000006279247)\n",
        "\n",
        "- [L'article L.\\ 342-2 du code de la propriété intellectuelle](https://www.legifrance.gouv.fr/codes/article_lc/LEGIARTI000006279250)\n",
        "\n",
        ". . .\n",
        "\n",
        "- L'[article 323-3 du code pénal](https://www.legifrance.gouv.fr/codes/article_lc/LEGIARTI000030939448) : _\"Le fait [...] d'extraire, de détenir, de reproduire [...] frauduleusement les données qu'il [le site] contient est puni de cinq ans d'emprisonnement et de 150 000 € d'amende\"_\n",
        "\n",
        ". . .\n",
        "\n",
        "- En termes de droit de la concurrence, on pourra aussi parler de concurrence déloyale avec l'[article L.\\ 121-1 du code de la consommation](https://www.legifrance.gouv.fr/codes/article_lc/LEGIARTI000032227301/)\n",
        "\n",
        ". . .\n",
        "\n",
        "- Il serait même possible de parler de parasitisme et invoquer l’[article 1240 du code civil](https://www.legifrance.gouv.fr/codes/article_lc/LEGIARTI000032041571)\n",
        "\n",
        ". . .\n",
        "\n",
        "- La `CNIL` a également publié en 2020 un ensemble de [nouvelles directives](https://www.cnil.fr/fr/la-reutilisation-des-donnees-publiquement-accessibles-en-ligne-des-fins-de-demarchage-commercial), limitant l'usage de données personnelles, même si publiques, à usage commercial\n",
        "\n",
        "\n",
        "## Les principales réglementations autour du web scraping {.smaller}\n",
        "\n",
        "#### En Europe (1/2)\n",
        "\n",
        "- La [Directive 96/9/CE](https://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:31996L0009:fr:HTML) du Parlement Européen et du conseil\n",
        "    + Elle introduit notamment le droit [sui generis](https://fr.wikipedia.org/wiki/Sui_generis), protégeant les bases de données ayant nécessité un _\"investissement substantiel\"_\n",
        "\n",
        "    + >  Le fabricant d’une base de données [a] le droit d’interdire l’extraction et/ou la réutilisation de la totalité ou d’une partie substantielle, évaluée de façon qualitative ou quantitative, du contenu de celle-ci, lorsque l’obtention, la vérification ou la présentation de ce contenu attestent un investissement substantiel du point de vue qualitatif ou quantitatif\n",
        "\n",
        "    + > L’extraction et/ou la réutilisation répétées et systématiques de parties non substantielles du contenu de la base de données qui supposeraient des actes contraires à une exploitation normale de cette base, ou qui causeraient un préjudice injustifié aux intérêts légitimes du fabricant de la base, ne sont pas autorisées\n",
        "\n",
        "\n",
        "## Les principales réglementations autour du web scraping {.smaller}\n",
        "\n",
        "#### En Europe (2/2)\n",
        "\n",
        "<br>\n",
        "\n",
        "- Le [RGPD](https://www.cnil.fr/fr/reglement-europeen-protection-donnees), sur l'utilisation des données à caractère personnel\n",
        "    + Règlement européen mais d'application extraterritoriale\n",
        "    + [5 grands principes](https://www.cnil.fr/fr/cnil-direct/question/quels-sont-les-grands-principes-des-regles-de-protection-des-donnees) :\n",
        "        - Le principe de finalité\n",
        "        - Le principe de proportionnalité et de pertinence\n",
        "        - Le principe d'une durée de conservation limitée\n",
        "        - Le principe de sécurité et de confidentialité\n",
        "        - Les droits des personnes \n",
        "\n",
        ". . .\n",
        "\n",
        "- Le [Data Governance Act](https://info.haas-avocats.com/droit-digital/data-governance-act-reglement-europeen), prévu pour septembre 2023\n",
        "\n",
        "\n",
        "## Les principales réglementations autour du web scraping {.smaller}\n",
        "\n",
        "#### Encore d'autres\n",
        "\n",
        "<br>\n",
        "\n",
        "- Les __jurisprudences__ issues des procès d'entreprises liés au web scraping\n",
        "\n",
        ". . .\n",
        "\n",
        "- Les mentions légales, conditions d'utilisation et autres consignes des sites concernés\n",
        "    + D'autant plus engageantes quand accéder au contenu nécessite d'accepter explicitement les conditions du site (par exemple en appuyant sur un bouton)\n",
        "\n",
        ". . .\n",
        "\n",
        "- Aux États-Unis, plusieurs textes peuvent s'appliquer, entre autres :\n",
        "    + Le [California Consumer Privacy Act](https://oag.ca.gov/privacy/ccpa)\n",
        "    + Le [Computer Fraud and Abuse Act](https://www.nacdl.org/Landing/ComputerFraudandAbuseAct)\n",
        "\n",
        "\n",
        "## Les sites se protègent aussi eux-mêmes\n",
        "\n",
        "<br>\n",
        "\n",
        "- Afin d'éviter la réutilisation de leurs contenus par des concurrents et lutter contre l'espionnage\n",
        "\n",
        ". . .\n",
        "\n",
        "- Afin de bloquer les `bots` qui occupent une partie significative du trafic, ralentissant ainsi l'accès au site\n",
        "    + Un scraping mal fait peut s'assimiler à une [attaque par déni de service](https://fr.wikipedia.org/wiki/Attaque_par_d%C3%A9ni_de_service) (`DoS`)\n",
        "\n",
        "\n",
        "## Les méthodes mises en place pour se protéger du scraping (1/2) {.smaller}\n",
        "\n",
        "<br>\n",
        "\n",
        "- Mettre en place des [__conditions d'utilisation__]{.blue2} contraignantes et instructions explicites pour se protéger d'un point de vue légal\n",
        "\n",
        ". . .\n",
        "\n",
        "- Repérer les [__adresses IP suspectes__]{.blue2} et [__bloquer leur accès__]{.blue2} au site, temporairement ou de façon permanente\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Identifier les bots__]{.blue2} et leur afficher un contenu différent des utilisateurs classiques, pour par exemple [__renvoyer de fausses données__]{.blue2}\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Limiter les requêtes ou la bande passante consommée__]{.blue2} par une même source, pouvant ainsi conduire à des collectes partielles ou interrompues\n",
        "\n",
        "\n",
        "## Les méthodes mises en place pour se protéger du scraping (2/2)\n",
        "\n",
        "- [__Modifier régulièrement le format `HTML`__]{.blue2} du contenu pour empêcher l'automatisation du scraping par autrui\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Créer des pages [Honeypot](https://fr.wikipedia.org/wiki/Honeypot)__]{.blue2} qu'un humain ne visiterait jamais pour identifier puis bloquer des bots\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Utiliser des CAPTCHAs__]{.blue2} lorsqu'une activité suspecte est repérée\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Nécessiter une identification__]{.blue2} pour accéder au contenu du site\n",
        "\n",
        "\n",
        "## Les limites du web scraping {.smaller}\n",
        "\n",
        "- La qualité des données obtenues par scraping n'est pas toujours au rendez-vous.\n",
        "    + De plus, vérification manuelle à faire pour vérifier qu'un faux contenu n'a pas été renvoyé par le site.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Il faut 'lutter' contre les sites qui se défendent contre le scraping, ce qui n'est pas sans effort.\n",
        "    + Modifications manuelles des codes à faire régulièrement, rendant l'__automatisation très difficile__.\n",
        "    + Pérennité de la collecte au fil du temps incertaine.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Les risques légaux sont existants, et plus généralement cela peut nuire à l'image d'un INS. \n",
        "    + Il vaut mieux favoriser des relations de confiance avec les sites concernés.\n",
        "\n",
        ". . .\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Remarque\n",
        "\n",
        "Il est préférable de privilégier d'autres modes d'accès aux données lorsque cela est possible.\n",
        ":::\n",
        "\n",
        "\n",
        "## Dans ces conditions, quand envisager le web scraping ? {.smaller}\n",
        "\n",
        "<br>\n",
        "\n",
        "La politique de l'INSEE est de garder le web scraping comme __dernière option__. Les premières étapes recommandées sont d'abord de :\n",
        "\n",
        "- Demander directement aux sites concernés l'accès à leurs données et nouer d'éventuels partenariats, par exemple modulo une contrepartie\n",
        "\n",
        ". . .\n",
        "\n",
        "- Chercher s'il existe une [API](https://fr.wikipedia.org/wiki/Interface_de_programmation) du site permettant d'accéder aux données (ou la demander)\n",
        "\n",
        ". . .\n",
        "\n",
        "- Chercher des alternatives, comme accéder à des données similaires via un moyen moins contraignant\n",
        "\n",
        "\n",
        "## Pour un scraping éthique (et légal !)\n",
        "\n",
        "- Le web scraping reste malgré tout une nouvelle source de données très pratique dans le cas où aucune meilleure alternative ne se présente.\n",
        "    + Il ne faut donc pas s'en priver lorsque c'est techniquement et juridiquement propice.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Cependant, il existe des moyens de scraper de façon honnête, \"éthique\" et en minimisant la charge sur le site scrapé.\n",
        "    + Cela passe par exemple par __demander la permission__ aux sites à scraper, ce qui peut aussi conduire à un éventuel partenariat.\n",
        "\n",
        "\n",
        "## Les guidelines du `Système Statistique Européen` {.smaller}\n",
        "\n",
        "<br>\n",
        "\n",
        "- Un ensemble de recommandations principalement à destination des INS sur le point d'être publié\n",
        "\n",
        ". . .\n",
        "\n",
        "- Une [première version](https://ec.europa.eu/eurostat/cros/system/files/04_-_web_scraping_policy.doc) datant de février 2020 disponible en ligne\n",
        "\n",
        ". . .\n",
        "\n",
        "> In the context of the work on Big Data and Trusted Smart Statistics, the European Statistical System (ESS) increasingly utilises information published on the World Wide Web. To ensure that web scraping activities of European Statistical System (ESS) members, namely Eurostat and the national statistical institutes (NSIs) are carried out transparently, and in line with ethical and legal provision, this document proposes guidelines for an ESS wide web scraping policy. Once adopted, these guidelines not only foster nationally sound practices but also ensure a consistent approach across the ESS.\n",
        "\n",
        "\n",
        "## Les guidelines du `Système Statistique Européen`\n",
        "\n",
        "#### Transparence\n",
        "\n",
        "- Rendre publique la liste des collectes de données par scraping de l'INS, autrement dit être [__transparent__]{.blue2}\n",
        "\n",
        ". . .\n",
        "\n",
        "- Si l'impact sur site va être important (par exemple un scraping fait très fréquemment), [__informer spécifiquement le site concerné__]{.blue2}\n",
        "    + Plus généralement, prendre le réflexe de demander la permission\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__S'identifier__]{.blue2} auprès du site lors de l'opération de scraping\n",
        "\n",
        "\n",
        "## Les guidelines du `Système Statistique Européen`\n",
        "\n",
        "#### Minimiser l'impact\n",
        "\n",
        "- Toujours chercher à [__minimiser l'impact__]{.blue2} sur les serveurs du site scrapé\n",
        "    + Notamment en [__limitant les requêtes__]{.blue2} effectuées au minimum requis\n",
        "\n",
        ". . .\n",
        "\n",
        "- Privilégier les [__heures creuses__]{.blue2} du site pour les opérations automatisées de scraping\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Étaler les requêtes__]{.blue2} en laissant un temps de 'pause' entre chaque requête, surtout sur un même domaine\n",
        "\n",
        "\n",
        "## Les guidelines du `Système Statistique Européen`\n",
        "\n",
        "#### Confiance\n",
        "\n",
        "- [__Favoriser les échanges__]{.blue2} avec les propriétaires des sites : partenariats, échanges de données, requêtes d'API, ...\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Se plier aux conditions d'utilisation__]{.blue2} des sites concernés et aux réglementations de la zone concernée\n",
        "\n",
        ". . .\n",
        "\n",
        "- Manipuler de façon sécurisée les données scrapées, notamment les données personnelles\n",
        "    + Ex : [__Respecter le RGPD__]{.blue2}, d'application extraterritoriale\n",
        "\n",
        "\n",
        "## ⚠️ Ce qu'il ne faut pas faire ! {.smaller}\n",
        "\n",
        "<br>\n",
        "\n",
        "- Consciemment déroger aux réglementations applicables et manquer de transparence\n",
        "\n",
        ". . .\n",
        "\n",
        "- Surcharger les requêtes sur le site concerné (assimilable à une attaque `DoS`) ou multiplier les mêmes requêtes plusieurs fois\n",
        "\n",
        ". . .\n",
        "\n",
        "- Scraper un site entier lorsque l'on a seulement besoin d'une portion de son contenu\n",
        "\n",
        ". . .\n",
        "\n",
        "- Paralléliser les requêtes sur un site ou faire ces dernières en heures pleines\n",
        "\n",
        ". . .\n",
        "\n",
        "- Diffuser de façon non autorisée des données scrapées non publiques ou soumises à droit d'auteur\n",
        "\n",
        ". . .\n",
        "\n",
        "- Pour un INS, utiliser le scraping à des fins non statistiques ou hors du champ légal\n",
        "\n",
        "\n",
        "## Avertissements {.smaller}\n",
        "\n",
        "- Selon les pays, il existe des données qui sont publiques mais dont le scraping est illégal.\n",
        "    + Il faut donc bien se renseigner sur les lois locales.\n",
        "    + Par exemple, la collecte d'adresses mail par scraping est illégale en Australie, en raison du [Spam Act](https://en.wikipedia.org/wiki/Spam_Act_2003) de 2003.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Dans le doute, ne pas hésiter à se documenter davantage.\n",
        "    - Exemples de ressources : [Carpentries](https://librarycarpentry.org/lc-webscraping/05-conclusion/index.html), [Rubyroidlabs](https://rubyroidlabs.com/blog/2016/04/web-scraping-1/)...\n",
        "\n",
        ". . .\n",
        "\n",
        "- Il existe parfois des structures dont le rôle est justement d'évaluer l'aspect juridique de pratiques comme le web scraping.\n",
        "    + A l'INSEE, c'est la responsabilité de l'[UAJC](https://lannuaire.service-public.fr/gouvernement/bd0be1df-7153-44b0-ab29-43d125837532)\n",
        "\n",
        ". . .\n",
        "\n",
        "- Outre l'aspect juridique, il faut bien passer en revue les impacts méthodologiques liés aux risques techniques du web scraping (collecte incomplète, rupture de collecte).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Rappels sur `HTML` {#01_03}\n",
        "\n",
        "## Comprendre la nature d'une page web {.smaller}\n",
        "\n",
        "- Un site Internet est constitué de diverses __pages Web__.\n",
        "   + Celles-ci sont le produit de fichiers appelés __codes source__ des pages.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Les 3 langages principaux pour les coder sont :\n",
        "    + [HTML](https://developer.mozilla.org/fr/docs/Web/HTML) : pour composer la structure des pages via un système de balises\n",
        "    + [CSS](https://developer.mozilla.org/fr/docs/Web/CSS) : des feuilles de style pour décrire la présentation de pages `HTML`\n",
        "    + [JavaScript](https://developer.mozilla.org/fr/docs/Web/JavaScript) : pour tout ce qui est relatif à l'interactivité d'un site (ex : boutons)\n",
        "\n",
        ". . .\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Pour en apprendre plus\n",
        "\n",
        "Deux ressources-clés :\n",
        "\n",
        "- [W3C](https://www.w3.org/) : World Wide Web Consortium\n",
        "- [MDN Web Docs](https://developer.mozilla.org/fr/docs/Learn/Getting_started_with_the_web) : Mozilla Developer Network\n",
        ":::\n",
        "\n",
        "## Inspecter une page web\n",
        "\n",
        "<br>\n",
        "\n",
        "- Il est possible d'afficher le __code source__ des pages Web, au sein duquel les scrapeurs doivent naviguer.\n",
        "\n",
        "<br>\n",
        "\n",
        "- `Clic droit` sur la page puis\n",
        "    + _\"Inspecter l'élément\"_ pour observer un endroit spécifique de la page\n",
        "    + _\"Afficher le code source de la page\"_ pour afficher le code de toute la page\n",
        "\n",
        "\n",
        "## Hiérarchisation d'une page web {.smaller}\n",
        "\n",
        "#### Les balises `HTML`\n",
        "\n",
        "<br>\n",
        "\n",
        "- Sur une page web, vous trouverez à coup sûr des éléments comme ``<head>``, ``<title>``, etc. Il  s'agit des codes qui vous permettent de structurer le contenu d'une page `HTML` et qui s'appellent des **balises**. \n",
        "    + Par exemple, les balises ``<p>``, ``<h1>``, ``<h2>``, ``<h3>``, ``<strong>`` ou ``<em>``.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Le symbole ``< >`` est une balise : il sert à indiquer le début d'une partie. Le symbole ``</ >`` indique la fin de cette partie.\n",
        "\n",
        ". . .\n",
        "\n",
        "- La plupart des balises vont par paires, avec une *balise ouvrante* et une *balise fermante* (par exemple ``<p>`` et ``</p>``).\n",
        "\n",
        "\n",
        "## Exemple : les balises de tableau\n",
        "\n",
        "<br>\n",
        "\n",
        "| Balise      | Description                        |\n",
        "|-------------|------------------------------------|\n",
        "| `<table>`   | Tableau                            |\n",
        "| `<caption>` | Titre du tableau                   |\n",
        "| `<tr>`      | Ligne de tableau                   |\n",
        "| `<th>`      | Cellule d'en-tête                  |\n",
        "| `<td>`      | Cellule                            |\n",
        "| `<thead>`   | Section de l'en-tête du tableau    |\n",
        "| `<tbody>`   | Section du corps du tableau        |\n",
        "| `<tfoot>`   | Section du pied du tableau         |\n",
        "\n",
        "\n",
        "## Un exemple : un tableau `HTML`\n",
        "\n",
        "<br>\n",
        "\n",
        "```{html}\n",
        "<table>\n",
        "<caption> Le Titre de mon tableau </caption>\n",
        "   <tr>\n",
        "      <th>Prénom</th>\n",
        "      <th>Nom</th>\n",
        "      <th>Profession</th>\n",
        "   </tr>\n",
        "   <tr>\n",
        "      <td>Mike </td>\n",
        "      <td>Stuntman</td>\n",
        "      <td>Cascadeur</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "      <td>Mister</td>\n",
        "      <td>Pink</td>\n",
        "      <td>Gangster</td>\n",
        "   </tr>\n",
        "</table>\n",
        "```\n",
        "\n",
        "## Un exemple : un tableau `HTML`\n",
        "\n",
        "<br>\n",
        "\n",
        "<table>\n",
        "<caption> Le Titre de mon tableau </caption>\n",
        "\n",
        "   <tr>\n",
        "      <th>Prénom</th>\n",
        "      <th>Nom</th>\n",
        "      <th>Profession</th>\n",
        "   </tr>\n",
        "   <tr>\n",
        "      <td>Mike </td>\n",
        "      <td>Stuntman</td>\n",
        "      <td>Cascadeur</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "      <td>Mister</td>\n",
        "      <td>Pink</td>\n",
        "      <td>Gangster</td>\n",
        "   </tr>\n",
        "</table>\n",
        "\n",
        "\n",
        "## Scraping d'une page web\n",
        "\n",
        "<br>\n",
        "\n",
        "- Le web scraping consiste à naviguer parmi ces balises `HTML` pour extraire le contenu désiré (textes, tableaux, images, ...).\n",
        "\n",
        ". . .\n",
        "\n",
        "- Il est aussi possible de récupérer d'autres url sur une page pour s'y rendre et les scraper ensuite.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Dans certains cas plus complexes, lire le contenu `HTML` ne suffit pas,\n",
        "   + Par exemple s'il faut cliquer sur des boutons pour faire apparaître le contenu désiré.\n",
        "\n",
        "\n",
        "## [XPath](https://librarycarpentry.org/lc-webscraping/02-xpath/index.html)\n",
        "\n",
        "<br>\n",
        "\n",
        "- Une page web peut aussi se présenter sous le format `XML`, proche du `HTML`.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Afin de justement naviguer dans une page `HTML` ou `XML`, on fait appel à un langage d'expressions appelé `XPath`.\n",
        "   + Ce sont des expressions `XPath` qui seront utilisées en appel des fonctions.\n",
        "   + `XPath` permet ainsi de se déplacer de noeud en noeud dans la structure arborescente d'une page.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# II. Mise en pratique {#index_02}\n",
        "\n",
        "# II. Sommaire\n",
        "\n",
        "<br>\n",
        "\n",
        "[Présentation des différentes librairies](#02_01)\n",
        "\n",
        "[Partie pratique](#02_02)\n",
        "\n",
        "[Aspects techniques du scraping éthique](#02_03)\n",
        "\n",
        "[Automatisation et industrialisation](#02_04)\n",
        "\n",
        "\n",
        "# Présentation des différentes librairies {#02_01}\n",
        "\n",
        "## Les [librairies principales](https://www.projectpro.io/article/python-libraries-for-web-scraping/625#mcetoc_1gb5hj7o81i) sur `Python`\n",
        "\n",
        "<br>\n",
        "\n",
        "Plusieurs librairies permettent de faire du scraping en `Python`. Les principales sont :\n",
        "\n",
        "- [Requests](https://requests.readthedocs.io/en/latest/)\n",
        "- [Urllib](https://docs.python.org/fr/3/library/urllib.html)\n",
        "- [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
        "- [Selenium](https://selenium-python.readthedocs.io/)\n",
        "- [Scrapy](https://scrapy.org/)\n",
        "\n",
        "\n",
        "## Extraire les codes sources HTML\n",
        "\n",
        "#### `Requests` et `Urllib`\n",
        "\n",
        "<br>\n",
        "\n",
        "- Rôle :\n",
        "    + Créer des requêtes `HTTP` pour récupérer le contenu des pages web\n",
        "    + Des _headers_ peuvent être ajoutés aux requêtes pour s'identifier auprès du site\n",
        "\n",
        ". . .\n",
        "\n",
        "- `Requests` un peu plus simpliste que `Urllib`\n",
        "\n",
        "\n",
        "## Analyser les codes _HTML_ : `BeautifulSoup`\n",
        "\n",
        "- Permet de formater des documents `HTML` ou `XML` en une structure arborescente\n",
        "- Permet ensuite de naviguer dans la structure pour scraper le contenu désiré\n",
        "- Très intuitif à utiliser\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Remarque\n",
        "\n",
        "La librairie se trouve généralement sous le nom de `bs4`.\n",
        ":::\n",
        "\n",
        "\n",
        "## Interagir avec une page : `Selenium`\n",
        "\n",
        "<br>\n",
        "\n",
        "- Les librairies précédentes ne permettent pas d'interagir avec une page utilisant `Javascript`\n",
        "    - Ex: Appuyer sur un bouton, rentrer ses identifiants, ...\n",
        "\n",
        ". . .\n",
        "\n",
        "- `Selenium` permet de simuler un navigateur (aussi appelé [headless browser](https://en.wikipedia.org/wiki/Headless_browser)) puis d'interagir avec les éléments `JavaScript` du site \"comme un utilisateur\"\n",
        "\n",
        "\n",
        "## Un outil plus complet : `Scrapy`\n",
        "\n",
        "<br>\n",
        "\n",
        "- Un outil plus complet mais aussi plus complexe\n",
        "- Très utile pour les opérations de web crawling\n",
        "- Davantage recommandé pour de gros projets\n",
        "- Un tutoriel des [Carpentries](https://librarycarpentry.org/lc-webscraping/04-scrapy/index.html)\n",
        "\n",
        "\n",
        "## Quelques librairies sur `R`\n",
        "\n",
        "- [polite](https://cran.r-project.org/web/packages/polite/index.html)\n",
        "    - Particulièrement orienté scraping éthique\n",
        "\n",
        ". . .\n",
        "\n",
        "- [rvest](https://thinkr.fr/rvest/)\n",
        "    - Librairie la plus utilisée et donc documentée\n",
        "\n",
        ". . .\n",
        "\n",
        "- D'autres librairies : [RCrawler](https://cran.r-project.org/web/packages/Rcrawler/Rcrawler.pdf), [RSelenium](https://cran.r-project.org/web/packages/RSelenium/index.html)\n",
        "\n",
        ". . .\n",
        "\n",
        "- Pour manipuler des headless browsers à très bas niveau, voir [Chromote](https://github.com/rstudio/chromote)\n",
        "    + Aussi disponbile sur Python [ici](https://pypi.org/project/chromote/)\n",
        "\n",
        "\n",
        "## Quelques librairies en `Java`\n",
        "\n",
        "<br>\n",
        "\n",
        "- `Java` est également beaucoup utilisé dans le domaine du web scraping\n",
        "\n",
        "<br>\n",
        "\n",
        "- Documentation extensive disponible sur Internet\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Partie pratique {#02_02}\n",
        "\n",
        "## Une plateforme de travail : le [SSP Cloud](https://datalab.sspcloud.fr/home)\n",
        "\n",
        "<br>\n",
        "\n",
        "![](img/macbook_onyxia.png){fig-align=\"center\"}\n",
        "\n",
        "\n",
        "## Un Datalab pour l'expérimentation et la formation\n",
        "\n",
        "- Plateforme de datascience dimensionnée pour les usages innovants\n",
        "\n",
        ". . .\n",
        "\n",
        "- Des technologies modernes qui favorisent la reproductibilité\n",
        "\n",
        ". . .\n",
        "\n",
        "- Lieu de formation et d'expérimentation\n",
        "\n",
        ". . .\n",
        "\n",
        "- Ouverte et collaborative\n",
        "\n",
        "\n",
        "## Du libre-service à la mise en production\n",
        "\n",
        "![](img/onyxia_galaxy.png){fig-align=\"center\"}\n",
        "\n",
        "\n",
        "## Le projet [Onyxia](https://www.onyxia.sh/)\n",
        "\n",
        "- Un projet open-source pour déployer des plateformes de datascience modernes\n",
        "\n",
        "![](img/onyxia_instances.png){fig-align=\"center\"}\n",
        "\n",
        ". . .\n",
        "\n",
        "- Le dépôt Github [ici](https://github.com/InseeFrLab/onyxia)\n",
        "\n",
        "\n",
        "## De la formation\n",
        "\n",
        "<br>\n",
        "\n",
        "- Le [catalogue de formation](https://www.sspcloud.fr/formation) du SSP Cloud\n",
        "  - Des formations reproductibles\n",
        "  - Un catalogue contributif\n",
        "\n",
        ". . . \n",
        "\n",
        "- Innover sur les modes de formation\n",
        "  - Vers de l'auto-formation tutorée\n",
        "\n",
        "\n",
        "## De l'open-source\n",
        "\n",
        "- Comptes GitHub institutionnels\n",
        "  - [InseeFr](https://github.com/InseeFr)\n",
        "  - [InseeFrLab](https://github.com/InseeFrLab)\n",
        "\n",
        ". . . \n",
        "\n",
        "- Pourquoi ouvrir ses codes ?\n",
        "  - Auditabilité des agents publics\n",
        "  - Meilleur qualité du code et reproductibilité\n",
        "  - Une vitrine pour l'auteur.e et pour l'INS\n",
        "\n",
        ". . .\n",
        "\n",
        "- Pour plus d'informations, contacter [innovation@insee.fr](mailto:innovation@insee.fr)\n",
        "\n",
        "\n",
        "## Comment utiliser le [SSP Cloud](https://datalab.sspcloud.fr/home) ?\n",
        "\n",
        "<br>\n",
        "\n",
        "- Une [documentation](https://docs.sspcloud.fr/onyxia-guide/decouverte-du-datalab) très complète\n",
        "\n",
        ". . .\n",
        "\n",
        "<br>\n",
        "\n",
        "- Démonstration en direct !\n",
        "\n",
        "\n",
        "## Mise en pratique : se familiariser à BeautifulSoup et Selenium\n",
        "\n",
        "- Une mise en pratique créée à destination des étudiants de Master de l'[ENSAE Paris](https://www.ensae.fr/)\n",
        "    + Incluant notamment les Administrateurs de l'INSEE en formation\n",
        "\n",
        "- Le lien pour accéder au TP de web scraping [__ici__](https://pythonds.linogaliana.fr/webscraping/)\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Pour aller plus loin\n",
        "\n",
        "- Un [site](https://pythonds.linogaliana.fr/course/) dédié à l'utilisation de Python pour la data science\n",
        "\n",
        "- Créé et entretenu par [Lino Galiana](https://github.com/linogaliana/), data scientist à l'INSEE\n",
        ":::\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Aspects techniques du scraping éthique {#02_03}\n",
        "\n",
        "## Les guidelines du `SSE` {.smaller}\n",
        "\n",
        "#### S'identifier\n",
        "\n",
        "- S'identifier via le champ [\"user-agent\"](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/User-Agent), l'un des _headers_ renseignables lors d'une requête `HTTP`\n",
        "\n",
        "- Un autre champ parmi les _headers_ possible : `from`\n",
        "\n",
        ". . .\n",
        "\n",
        "- Renseigner son nom, entité, coordonnées\n",
        "\n",
        "- On peut aussi inclure l'url contenant les informations liées à la collecte ou une explication sur les données prélevées\n",
        "\n",
        ". . .\n",
        "\n",
        "::: {.callout-tip}\n",
        "## Exemple avec `Python` et `requests`\n",
        "\n",
        "```python\n",
        "\n",
        "url = 'abc.com'\n",
        "\n",
        "headers = {\n",
        "    'User-Agent': 'Antoine Palazzolo - antoine.palazzolo@insee.fr - INSEE - Collect xxx in order to do yyy',\n",
        "    'From': 'More information on insee.fr/zzz'\n",
        "}\n",
        "\n",
        "request_text = requests.get(url, headers=headers).text\n",
        "```\n",
        ":::\n",
        "\n",
        "## Les guidelines du `SSE` {.smaller}\n",
        "\n",
        "#### Suivre les conventions\n",
        "\n",
        "- Il existe plusieurs conventions liées à l'utilisation d'Internet et du scraping qu'il faut tâcher de respecter.\n",
        "\n",
        "- On citera le [Word Wide Web Consurtium](https://www.w3.org/TR/dwbp/) (`W3C`), notamment sur les protocoles de transfert hypertexte.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Essentiel pour le scraping, il est vivement recommandé de se plier au [protocole d'exclusion des robots](https://en.wikipedia.org/wiki/Robots_exclusion_standard).\n",
        "    + En tapant la racine de l'url suivi de '/robots.txt', on peut accéder à une page du site indiquant les règles que doit respecter un programme pour accéder au site, les pages pouvant être scrapées, celles qui ne doivent pas l’être, la charge acceptable de scraping (fréquence des requêtes par exemple)...\n",
        "    + Exemple: [https://fr.wikipedia.org/__robots.txt__]{.orange}\n",
        "    + Les crawlers peuvent lire ces fichiers et s'y plier d'eux-mêmes (cf [IBM](https://www.ibm.com/docs/en/wca/3.5.0?topic=crawlers-how-web-crawler-uses-robots-exclusion-protocol)).\n",
        "    + Davantages d'informations et explications techniques [ici](https://www.robotstxt.org/robotstxt.html)\n",
        "\n",
        "\n",
        "## Contourner les défenses des sites {.smaller}\n",
        "\n",
        "<br>\n",
        "\n",
        "Quelques pratiques admises pour ne pas être bloqué par les sites scrapés :\n",
        "\n",
        ". . .\n",
        "\n",
        "- Ajouter des pauses entre chaque requête, pour ne pas aller plus vite qu'un utilisateur ne le pourrait (`time.sleep()` en `Python`)\n",
        "    + C'est également une bonne pratique de scraping éthique\n",
        "    + Un délai de 2 et 5 secondes par requête est la préconisation usuelle\n",
        "\n",
        ". . .\n",
        "\n",
        "- Modifier régulièrement le champ user-agent (par exemple avec un compteur) avant que celui-ci ne se fasse bloquer\n",
        "\n",
        "\n",
        "## Autres recommandations pour un INS {.smaller}\n",
        "\n",
        "<br>\n",
        "\n",
        "- Faire en sorte de pouvoir tracer l’activité d’un programme, afin de notamment pouvoir en auditer le fonctionnement.\n",
        "    + Les logs doivent contenir des informations sur l’utilisateur ou le compte système effectuant l’action, le résultat de l’action et le temps qu’elle a mis à s’exécuter.\n",
        "\n",
        ". . .\n",
        "\n",
        "- En cas de passage en production, il est nécessaire que le programme fasse l’objet d’une revue de code (entre pairs ou externe), voire, selon la nature de son intégration, relève d’une démarche d’homologation de sécurité.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Automatisation et industrialisation {#02_04}\n",
        "\n",
        "## Pré-requis\n",
        "\n",
        "<br>\n",
        "\n",
        "- Accès Internet au sein de l'INS avec un proxy bien configuré si existant\n",
        "\n",
        ". . .\n",
        "\n",
        "- Les sites scrapés doivent être dans l'allow-list et ne doivent pas avoir déjà bloqué l'adresse IP\n",
        "\n",
        "\n",
        "## Automatiser et industrialiser les processus de scraping\n",
        "\n",
        "- En raison des efforts des sites contre le scraping (ex : format des sites changeant régulièrement, blocage des adresses IP),\n",
        "    + Limiter les interactions humaines est quasiment impossible\n",
        "    + Industrialiser les processus nécessite des révisions régulières\n",
        "\n",
        ". . .\n",
        "\n",
        "- Automatiser les méthodes peut reposer sur un [cronjob](https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/) ou autre orchestrateur\n",
        "\n",
        "\n",
        "## Stocker les données\n",
        "\n",
        "- En général, les données brutes (ex : les pages web) sont stockées dans une base `NoSQL` et sont traitées ensuite.\n",
        "    - Les codes `HTML` peuvent par exemple être stockés dans une base `MongoDB`.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Problèmes méthodologiques courants :\n",
        "    - __Différencier le stock du flux__ : la page web que je viens de scraper est-elle nouvelle ou est-ce la même que celle d’hier ?\n",
        "    - __Dédoublonner le contenu__ lorsque par exemple le scraping se fait sur plusieurs sites dont le contenu peut s'intersecter.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# III. Divers cas d'usage {#index_03}\n",
        "\n",
        "# III. Sommaire\n",
        "\n",
        "<br>\n",
        "\n",
        "[Quelques litiges légaux](#03_01)\n",
        "\n",
        "[Le scraping à l'INSEE](#03_02)\n",
        "\n",
        "[Cas d'usage à l'INSEE](#03_03)\n",
        "\n",
        "\n",
        "# Quelques litiges légaux {#03_01}\n",
        "\n",
        "## [LinkedIn v. HiQ Labs (2019)](https://www.silicon.fr/linkedin-cour-supreme-americaine-linkedin-410279.html) {.smaller}\n",
        "\n",
        "#### Le litige\n",
        "\n",
        "<br>\n",
        "\n",
        "- [__Contexte__]{.blue2} : HiQ scrape les données des utilisateurs LinkedIn (accessibles publiquement) pour nourrir un outil de prédiction de l'attrition, commercialisé ensuite.\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Cas__]{.blue2} :\n",
        "    + LinkedIn tente d'interdire la collecte au nom du [CFAA](https://www.nacdl.org/Landing/ComputerFraudandAbuseAct) et d'une violation des conditions d'utilisation du site.\n",
        "    + HiQ saisit la justice pour se défendre.\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Verdict__]{.blue2} : Deux victoires (tribunal californien et Cour Suprême) pour HiQ, dont le maintien de l'activité de scraping est autorisé.\n",
        "\n",
        "\n",
        "## [LinkedIn v. HiQ Labs (2019)](https://www.csoonline.com/article/3662039/hiq-v-linkedin-court-ruling-will-have-a-material-effect-on-privacy.html) {.smaller}\n",
        "\n",
        "#### Les conclusions\n",
        "\n",
        "<br>\n",
        "\n",
        "- LinkedIn n'est pas propriétaire des données : ce sont en réalité les membres eux-mêmes. Les utilisateurs qui choisissent un profil public attendent « évidemment » qu’il soit accessible par des tiers.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Laisser à LinkedIn le contrôle sur l’utilisation des données publiques pourrait engendrer un « monopole de l’information » préjudiciable à l’intérêt public.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Le `CFAA` est inadapté pour ce type de cas.\n",
        "\n",
        ". . .\n",
        "\n",
        "- HiQ n'a scrapé que des données auxquelles n'importe quel utilisateur a accès, et LinkedIn ne peut pas les leur interdire spécifiquement.\n",
        "\n",
        "\n",
        "## [Ryanair v. Opodo (2010)](https://www.legalis.net/jurisprudences/tribunal-de-grande-instance-de-paris-3eme-chambre-2eme-section-jugement-du-09-avril-2010/)\n",
        "\n",
        "#### Le litige\n",
        "\n",
        "- [__Contexte__]{.blue2} : Opodo scrape (entre autres) les données du site de Ryanair pour les agréger en un comparateur de prix de billets.\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Cas__]{.blue2} : Ryanair attaque Opodo en justice dans plusieurs pays européens, notamment en France, pour non respect des CGU, concurrence déloyale et parasitisme.\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Verdict__]{.blue2}  : Différent selon les pays, mais en France Ryanair a été débouté à deux reprises.\n",
        "\n",
        "\n",
        "## [Ryanair v. Opodo (2010)]{.orange}\n",
        "\n",
        "#### Les conclusions\n",
        "\n",
        "<br>\n",
        "\n",
        "Le Tribunal de Paris :\n",
        "\n",
        ". . .\n",
        "\n",
        "- Rejette l'intégralité des demandes de Ryanair\n",
        "\n",
        ". . .\n",
        "\n",
        "- Condamne Ryanair à d'importantes sommes à Opodo pour préjudice\n",
        "\n",
        ". . .\n",
        "\n",
        "- Maintient le droit d'Opodo à scraper les données publiques du site de Ryanair\n",
        "\n",
        "\n",
        "## [Ryanair v. PR Aviation (2015)](https://prezi.com/po5tmteybziv/ryanair-ltd-v-pr-aviation-bv/)\n",
        "\n",
        "#### Le litige\n",
        "\n",
        "<br>\n",
        "\n",
        "- [__Contexte__]{.blue2} : PR Aviation scrape (entre autres) les données du site de Ryanair pour les agréger en un comparateur de prix de billets.\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Cas__]{.blue2} : Ryanair attaque PR Aviation en justice aux Pays-Bas pour ne pas avoir respecté les termes contractuels d'utilisation du site et pour infraction aux directives européennes de protection des données.\n",
        "\n",
        "\n",
        "## [Ryanair v. PR Aviation (2015)](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A62014CJ0030) {.smaller}\n",
        "\n",
        "#### Les conclusions\n",
        "\n",
        "<br>\n",
        "\n",
        "Décision préliminaire de la [CJEU](https://european-union.europa.eu/institutions-law-budget/institutions-and-bodies/institutions-and-bodies-profiles/court-justice-european-union-cjeu_en) :\n",
        "\n",
        "- La `Directive 96/9/EC` ne s'applique pas dans ce cas, car les bases de données ne qualifient pas :\n",
        "    - Pour le droit au __copyright__\n",
        "    - Pour la protection __sui generis__\n",
        "\n",
        ". . .\n",
        "\n",
        "- En revanche, Ryanair est __autorisé à instaurer des limitations contractuelles__ sur l'utilisation de son site, tant qu'elles ne contradisent pas le droit national\n",
        "    + On notera que pour pouvoir lancer une recherche et visualiser les vols Ryanair disponibles en ligne, il faut explicitement accepter les CGU du site en cliquant sur un bouton\n",
        "\n",
        "\n",
        "## [Ryanair v. Expedia (2019)](https://skift.com/2019/09/24/ryanair-and-expedia-settle-screen-scraping-lawsuits-on-2-continents/)\n",
        "\n",
        "- [__Contexte__]{.blue2} : Expedia scrape (entre autres) les données du site de Ryanair pour les agréger sur son comparateur en ligne.\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Cas__]{.blue2} : Ryanair attaque PR Aviation en justice aux Etats-Unis et en Irlande pour ne pas avoir respecté les termes contractuels d'utilisation du site et au nom du CFAA aux Etats-Unis.\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Verdict__]{.blue2} : Accord \"à l'amiable\" entre les deux géants, mais les vols de Ryanair n'apparaissent plus sur le site d'Expedia.\n",
        "\n",
        "\n",
        "## [Ryanair v. Kiwi.com (2021)](https://www.expats.cz/czech-news/article/czech-ticket-seller-kiwi-com-wins-dispute-with-ryanair-over-handling-of-passenger-data)\n",
        "\n",
        "#### Le litige\n",
        "\n",
        "<br>\n",
        "\n",
        "- [__Contexte__]{.blue2} : Kiwi.com scrape (entre autres) les données du site de Ryanair pour les agréger sur son comparateur en ligne.\n",
        "\n",
        "- [__Cas__]{.blue2} : Ryanair attaque Kiwi.com en justice en République Tchèque pour ne pas avoir respecté les termes contractuels d'utilisation du site.\n",
        "\n",
        "- [__Verdict__]{.blue2} : Première défaite de Kiwi.com, puis victoire en appel auprès de la Cour Constitutionnelle Tchèque.\n",
        "\n",
        "\n",
        "## [Ryanair v. Kiwi.com (2021)]{.orange} {.smaller}\n",
        "\n",
        "#### Les conclusions\n",
        "\n",
        "<br>\n",
        "\n",
        "- La cour régionale de Brno avait imposé à Kiwi.com de se plier aux CGU de Ryanair. Cela impliquait notamment que Kiwi.com devait transmettre à Ryanair plusieurs données personnelles sur ses clients ayant acheté un billet de la compagnie sur la plateforme (dont par exemple leurs coordonnées).\n",
        "\n",
        ". . .\n",
        "\n",
        "- En cour d'appel, la décision avait été révoquée pour les raisons suivantes :\n",
        "    - Droit national à la protection judiciaire\n",
        "    - Liberté de conduire son entreprise\n",
        "    - Le procès initial n'aurait pas suffisamment tenu compte du contexte\n",
        "\n",
        "\n",
        "## [Ryanair v. Lastminute - Italie (2019)](https://www.travelmole.com/news/italian-supreme-court-rules-against-ryanair-in-favour-of-lastminute-com-owner/) {.smaller}\n",
        "\n",
        "<br>\n",
        "\n",
        "- [__Contexte__]{.blue2} : Lastminute scrape (entre autres) les données du site de Ryanair pour les agréger sur son comparateur en ligne.\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Cas__]{.blue2} :\n",
        "    + Ryanair attaque Lastminute en justice en Italie pour ne pas avoir respecté les CGU du site et le droit à la propriété intellectuelle.\n",
        "    + Ryanair demande également un accès aux données de Lastminute liées aux tickets de la compagnie.\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Verdict__]{.blue2} : La Cour Suprême prend le parti de Lastminute et n'autorise pas l'aspect contractuel des CGU de Ryanair ni l'accès aux données demandées.\n",
        "\n",
        "\n",
        "## [Ryanair v. Lastminute - France (2022)](https://www.tourmag.com/Ryanair-la-justice-interdit-a-Lastminute-de-vendre-les-billets-de-la-compagnie-_a114106.html)\n",
        "\n",
        "- [__Contexte__]{.blue2} : Lastminute scrape (entre autres) les données du site de Ryanair pour les agréger sur son comparateur en ligne.\n",
        "\n",
        "- [__Cas__]{.blue2} : Ryanair attaque Lastminute en justice en France pour ne pas avoir respecté les termes contractuels d'utilisation du site.\n",
        "\n",
        "- [__Verdict__]{.blue2} : La cour d'appel de Paris prend le parti de Ryanair et ordonne la cessation immédiate des activités de scraping de Lastminute, en plus de lourds dommages et intérêts.\n",
        "\n",
        "\n",
        "## [Affaire \"Bluetouff\" - France (2015)]{.orange}\n",
        "\n",
        "- [Cour de cassation, Chambre criminelle, 20 mai 2015, 14-81.336](https://www.legifrance.gouv.fr/juri/id/JURITEXT000030635061/)\n",
        "    - [Un exemple de décryptage](https://www.securitecloud.com/juridique/laffaire-bluetouff-decryptee-par-un-expert-judiciaire/)\n",
        "\n",
        "- Olivier Laurelli, alias Bluetouff, condamné à 3000 euros d'amende pour avoir téléchargé et réutilisé en 2012 (pour diffusion) des données de l'Anses accessibles publiquement sur leur site, là où elles n'auraient pas dû l'être.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Bluetoof relaxé par le tribunal de Créteil en 2012 puis condamné auprès de la Cour d'appel de Paris en 2015.\n",
        "\n",
        "\n",
        "## [LeBonCoin v. Entreparticuliers (2021)](https://cms.law/fr/fra/news-information/arret-leboncoin-web-scraping-droit-sui-generis-sur-les-bases-de-donnees)\n",
        "\n",
        "#### Le litige\n",
        "\n",
        "- [__Contexte__]{.blue2} : Entreparticuliers.com scrape quotidiennement les annonces immobilières présentes sur leboncoin.fr afin de les republier sur son propre site\n",
        "\n",
        "- [__Cas__]{.blue2} : LeBonCoin attaque en justice Entreparticuliers.com en France pour non respect du droit `sui generis` de ses bases de données\n",
        "\n",
        "- [__Verdict__]{.blue2} : Entreparticuliers.com condamné à deux reprises (par le Tribunal puis la Cour d'appel de Paris)\n",
        "\n",
        "\n",
        "## [LeBonCoin v. Entreparticuliers (2021)](https://www.doctrine.fr/d/CA/Paris/2021/C0E3F30A13EA86EFBEE37) {.smaller}\n",
        "\n",
        "#### Les conclusions (1/2)\n",
        "\n",
        "- Accéder au contenu du site LeBonCoin.fr ne nécessite pas d'accepter explicitement les CGU, LeBonCoin n'a donc pas invoqué le côté contractuel de ces dernières mais seulement le droit `sui generis`.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Pour en bénéficier, LeBonCoin a dû témoigner d'un _investissement substantiel_ dans la constitution, la vérification ou la présentation de ses bases de données.\n",
        "    + En pratique, c'est un point bloquant pour nombre de producteurs de données dans de telles affaires.\n",
        "    + En l'occurrence, il a été prouvé les moyens humains et financiers investis dans ces bases étaient bien substantiels.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Entreparticuliers a donc été condamné à deux reprises :\n",
        "    + Par le tribunal au nom de _l’article L.\\ 342-1 du Code de la propriété intellectuelle_\n",
        "    + Par la Cour d'appel au nom de _l’article L.\\ 342-2 du même Code_\n",
        "\n",
        "\n",
        "## [LeBonCoin v. Entreparticuliers (2021)]{.orange} {.smaller}\n",
        "\n",
        "#### Les conclusions (2/2)\n",
        "\n",
        "<br>\n",
        "\n",
        "- La Cour d'appel souligne que le but poursuivi lors du scraping est sans incidence pour caractériser l’atteinte au droit `sui generis`.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Entreparticuliers.com condamné à verser d'importants dommages et intérêts à leboncoin.fr pour :\n",
        "    + __Préjudice financier__ : LeBonCoin témoignant d'importants investissements dans la lutte contre le web scraping\n",
        "    + __Préjudice d'image__ : LeBonCoin démontrait un nombre important de plaintes de ses utilisateurs\n",
        "\n",
        "\n",
        "\n",
        "## D'autres litiges légaux en Europe\n",
        "\n",
        "<br>\n",
        "\n",
        "- [AutoTrack v. GasPedaal](https://curia.europa.eu/juris/document/document.jsf?docid=145914&doclang=FR) (2013 - Pays-Bas)\n",
        "    + Aussi connu sous le nom de [Innoweb BV v. Wegener ICT Media BV](https://eur-lex.europa.eu/legal-content/EN/TXT/?uri=CELEX%3A62012CA0202)\n",
        "    + Le métamoteur de recherche GasPedaal est interdit de scraper GasPedaal, notamment car :\n",
        "        - Les données scrapées sont réutilisées sans modification notoire\n",
        "        - AutoTrack bénéficie du droit `sui generis` sur ses données\n",
        "\n",
        "\n",
        "## D'autres litiges légaux aux Etats-Unis\n",
        "\n",
        "- [Craigslist Inc. v. 3Taps Inc.](https://en.wikipedia.org/wiki/Craigslist_Inc._v._3Taps_Inc.) ( 2013 - Etats-Unis)\n",
        "    - Suite à un accord mutuel, 3Taps et PadMapper ne pourront plus scraper les données de Craiglist et devront lui verser une somme importante d'argent.\n",
        "    - Le CFAA a été invoqué par Craiglist et accepté par la Cour suite au blocage des adresses IP des deux entreprises et les multiples mises en demeure envoyées pour cesser les activités de collecte. 3Taps avait continué ses activités de scraping en utilisant un VPN (et PadMapper les leur avait scrapées).\n",
        "\n",
        "\n",
        "## Conclusions des jurisprudences {.smaller}\n",
        "\n",
        "#### En Europe (1/2)\n",
        "\n",
        "- Les CGU d'un site sont juridiquement contractuels pour interdire toute pratique de web scraping ...\n",
        "    + ... au moins dès lors qu'elles sont acceptées explicitement (par exemple en appuyant sur un bouton) ...\n",
        "    + ... sauf si mention contraire par les lois nationales (ex : si supériorité du droit à la concurrence, déjà invoqué en Italie ou en République Tchèque).\n",
        "\n",
        ". . .\n",
        "\n",
        "- Republier des données scrapées ...\n",
        "    + au moins à des fins commerciales\n",
        "    + sans qu'un travail notable de réutilisation soit fait\n",
        "    + par exemple pour un méta-moteur de recherche\n",
        "    + pouvant créer un préjudice pour le site initial\n",
        "    \n",
        "    ... __n'est pas autorisé__.\n",
        "\n",
        "\n",
        "## Conclusions des jurisprudences\n",
        "\n",
        "#### En Europe (2/2)\n",
        "\n",
        "- Un contenu accessible publiquement, mais sans que ce ne soit manifestement un choix du site, ne peut pas forcément être légalement scrapé.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Le droit `sui generis` protège les bases de données nécessitant des investissements substantiels par les producteurs, indépendamment de l'intention des scrapeurs.\n",
        "    + En revanche, prouver la qualification à ce droit n'est pas tâche aisée.\n",
        "\n",
        "\n",
        "## Conclusions des jurisprudences - Aux Etats-Unis\n",
        "\n",
        "- Un site affichant des données publiques dont il n'est pas propriétaire ne peut pas en empêcher le scraping.\n",
        "\n",
        ". . .\n",
        "\n",
        "- L'activité de web scraping en elle-même ne viole pas le Computer Fraud and Abuse Act.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Lors d'un litige, bloquer l'adresse IP d'un utilisateur et lui adresser une mise en demeure interdisant le scraping du site peuvent éventuellement suffire à invoquer le CFAA pour protéger les bases de données du site.\n",
        "\n",
        "\n",
        "## Et pour un INS alors ? {.smaller}\n",
        "\n",
        "<br>\n",
        "\n",
        "Quid des prérogatives de puissance publique pour recueillir de l'information ?\n",
        "\n",
        ". . .\n",
        "\n",
        "<br>\n",
        "\n",
        "- En Europe, la [loi n° 633 du 22 avril 1941](https://wipolex-res.wipo.int/edocs/lexdocs/laws/fr/it/it099fr.html), pour la protection du droit d’auteur, prévoit une exception en cas d’utilisation d’une base de données à des fins de recherche scientifique à but non lucratif (art. 64-sexies de la loi n° 633/1941 modifié).\n",
        "    + Bien que la recherche et la production statistiques ne soient pas explicitement mentionnées, ces dispositions apportent un cadre raisonnable pour permettre aux statisticiens publics d’accéder aux informations des bases de données en ligne et pour traiter ces informations afin de produire des résultats statistiques anonymisés.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Le scraping à l'INSEE {#03_02}\n",
        "\n",
        "## Scraping à l'INSEE\n",
        "\n",
        "#### Quand ? \n",
        "\n",
        "<br>\n",
        "\n",
        "- Le web scraping est utilisé en __dernier recours__, l'INSEE favorisera :\n",
        "    + Les [__accords__]{.blue2} avec des partenaires (ex : seloger.com)\n",
        "    + L'utilisation d'[__API__]{.blue2} (ex : Qwant, Yahoo Finance)\n",
        "    + Les sources de [__données publiques__]{.blue2}\n",
        "\n",
        ". . .\n",
        "\n",
        "- Le web scraping devient cependant une source de données grandissante.\n",
        "\n",
        "\n",
        "## Scraping à l'INSEE\n",
        "\n",
        "#### Utilisation\n",
        "\n",
        "Le scraping est notamment utilisé pour le calcul des [__indices des prix__]{.blue2} :\n",
        "\n",
        ". . .\n",
        "\n",
        "- Prix des __transports__ (trains via site de la `SNCF`, domaine maritime) ;\n",
        "\n",
        ". . .\n",
        "\n",
        "- Prix de __produits divers__ (surtout de l'électronique) ;\n",
        "\n",
        ". . .\n",
        "\n",
        "- Prix dans le domaine de l'__hôtellerie__ (avec `booking.com`).\n",
        "\n",
        ". . .\n",
        "\n",
        "D'autres utilisations ponctuelles peuvent également être faites.\n",
        "\n",
        "\n",
        "## Scraping à l'INSEE\n",
        "\n",
        "#### Organisation\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "- Un scraping encore par cas d'usage, avec une gestion plus globale en cours de maturité\n",
        "    + Objectif de mutualisation entre les équipes statistiques\n",
        "    + La logique open source comme moyen de mutualisation\n",
        "\n",
        ". . .\n",
        "\n",
        "- Beaucoup de `Python`, un peu de `R` et de `Java`\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Cas d'usage à l'INSEE {#03_03}\n",
        "\n",
        "## Les prix dans le domaine de l'hôtellerie (`Booking.com`)\n",
        "\n",
        "#### Références\n",
        "\n",
        "- Un travail ayant donné lieu à une [publication](https://www.ottawagroup.org/Ottawa/ottawagroup.nsf/4a256353001af3ed4b2562bb00121564/90eefd961765454eca25886a00042203/$FILE/Web%20scraping%20of%20booking.com_Paper.pdf)\n",
        "    + Adrien [Montbroussous]{.blue2}, Camille [Freppel]{.blue2} and Ombéline [Guillon]{.blue2}, *\"Web scraping of a booking platform: exploring new data and methodology for the hotel service consumer price index\"*, _Paper for the 17th International Conference of the Ottawa Group, Rome_\n",
        "\n",
        "- Une présentation plus accessible [ici](http://www.jms-insee.fr/2022/S14_1_PPT_MONTBROUSSOUS_JMS2022.pdf)\n",
        "\n",
        "\n",
        "## Les prix dans le domaine de l'hôtellerie (`Booking.com`)\n",
        "\n",
        "#### Le code\n",
        "\n",
        "<br>\n",
        "\n",
        "- [__But__]{.blue2} : collecter davantage de données pour calculer au mieux les indices d'évolution de prix pour l'hôtellerie.\n",
        "\n",
        "- La partie 'scraping' du projet est disponible [ici](https://git.lab.sspcloud.fr/methodo-ipc/webscraping-hotel).\n",
        "\n",
        "- Pour plus d'informations, contacter [Adrien Montbroussous](mailto:adrien.montbroussous@insee.fr) (INSEE).\n",
        "\n",
        ". . .\n",
        "\n",
        "- La conférence associée aux présentations : [ici](https://www.ottawagroup.org/ottawa/ottawagroup.nsf/4a256353001af3ed4b2562bb00121564/c7e600e0bec85d82ca25888400059a93?OpenDocument#Meeting%2017%20Rome)\n",
        "    + D'autres projets similaires de scraping mentionnés\n",
        "\n",
        "\n",
        "## Ventes d'articles électroniques\n",
        "\n",
        "- [__But__]{.blue2} : collecter davantage de données pour calculer au mieux les indices de prix associés au secteur\n",
        "    + Projet encore à une étape expérimentale\n",
        "\n",
        ". . .\n",
        "\n",
        "- Scraping de [Boulanger](https://www.boulanger.com/) : [ici](https://git.lab.sspcloud.fr/methodo-ipc/webscraping-biens-electroniques/-/tree/master/boulanger)\n",
        "\n",
        ". . .\n",
        "\n",
        "- Scraping de [Rue du Commerce](https://www.rueducommerce.fr/) : [ici](https://git.lab.sspcloud.fr/methodo-ipc/webscraping-biens-electroniques/-/tree/master/rue-du-commerce)\n",
        "\n",
        ". . .\n",
        "\n",
        "- Pour plus d'informations, contacter [Adrien Montbroussous](mailto:adrien.montbroussous@insee.fr) (INSEE).\n",
        "\n",
        "\n",
        "## Scraping de la SNCF {.smaller}\n",
        "\n",
        "#### Contexte\n",
        "\n",
        "<br>\n",
        "\n",
        "- Le calcul de l'IPC tient compte de :\n",
        "    + L’indice des prix des trains Grandes Lignes\n",
        "    + Le transport des passagers en train\n",
        "\n",
        ". . .\n",
        "\n",
        "- Les prix utilisés étaient fondés sur un document publié annuellement par la SNCF. Mais cette méthode :\n",
        "    + Ne reflète pas les variations infra-annuelles réelles, en particulier pour les TGV\n",
        "    + Ne reflète pas les prix effectivement payés par les consommateurs\n",
        "    + Ne suit pas les recommandations des institutions internationales\n",
        "\n",
        "\n",
        "## Scraping de la SNCF {.smaller}\n",
        "\n",
        "#### Introduction du webscraping\n",
        "\n",
        "<br>\n",
        "\n",
        "- Sous forme expérimentale depuis 2018, indices publiés depuis 2020\n",
        "\n",
        ". . .\n",
        "\n",
        "- Collecte quotidienne pour capter la volatilité des prix\n",
        "\n",
        "- Requêtes effectuées pour plusieurs couples origine-destination, types de train, antériorités, profils passagers et horaires\n",
        "\n",
        "- Près de 23 000 requêtes par nuit\n",
        "\n",
        ". . .\n",
        "\n",
        "- Un important travail statistique avec les données ainsi obtenues s'ensuit.\n",
        "    + Stratification en cellules homogènes de prix\n",
        "    + Un micro-indice calculé par cellule\n",
        "    + Agrégation des micro-indices avec un indice de Laspeyres arithmétique\n",
        "\n",
        "\n",
        "## Scraping de la SNCF {.smaller}\n",
        "\n",
        "#### Comparaison des résultats\n",
        "\n",
        "![](img/scraping_sncf.png){fig-align=\"center\"}\n",
        "\n",
        "\n",
        "## D'autres ressources pour le scraping lié à l'`IPC`\n",
        "\n",
        "<br>\n",
        "\n",
        "- [Guidelines d'Eurostat](https://ec.europa.eu/eurostat/documents/272892/12032198/Guidelines-web-scraping-HICP-11-2020.pdf/) sur le scraping lié à l'indice des prix à la consommation\n",
        "    + Annexe 3 consacrée aux travaux de l'INSEE sur Boulanger et Rue du Commerce\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# IV. D'autres organisations adeptes de scraping {#index_04}\n",
        "\n",
        "# IV. Sommaire\n",
        "\n",
        "<br>\n",
        "\n",
        "[Le scraping chez Eurostat](#04_01)\n",
        "\n",
        "[Cas d'usage d'Eurostat](#04_02)\n",
        "\n",
        "[Web scraping dans un INS - Quelques interlocuteurs](#04_03)\n",
        "\n",
        "\n",
        "# Le scraping chez Eurostat {#04_01}\n",
        "\n",
        "## Les investissements d'Eurostat en web scraping\n",
        "\n",
        "- Eurostat investit dans divers projets communs nommés [ESSnets](https://ec.europa.eu/eurostat/cros/page/essnet_en).\n",
        "\n",
        "    > \"An ESSnet project is a network of several `ESS` organisations aimed at providing results that will be beneficial to the whole `ESS`.\"\n",
        "\n",
        ". . .\n",
        "\n",
        "- Parmi ces investissements, plusieurs liés aux nouvelles sources de données, dont le web scraping.\n",
        "    + ESSnet Big Data I & II\n",
        "    + Trusted Smart Statistics – Web Intelligence Network\n",
        "\n",
        "\n",
        "## Une continuité de projets\n",
        "\n",
        "3 ESSnets dans la continuité les uns des autres :\n",
        "\n",
        ". . .\n",
        "\n",
        "- [Big Data I](https://ec.europa.eu/eurostat/cros/essnet-big-data-1_en) de février 2016 à mai 2018\n",
        "\n",
        ". . .\n",
        "\n",
        "- [Big Data II](https://ec.europa.eu/eurostat/cros/essnet-big-data-2_en) de novembre 2018 à juin 2021\n",
        "\n",
        ". . .\n",
        "\n",
        "- Le [Web Intelligence Network](https://ec.europa.eu/eurostat/cros/content/project-overview_en) (`WIN`) d'avril 2020 à mars 2025\n",
        "    + Le `WIN` fait notamment la promotion du Web Intelligence Hub (`WIH`), dédié au thème de l'acquisition et l'utilisation de nouvelles données venant du Web.\n",
        "    + Ce sont 17 organisations de 14 pays européens qui travaillent ensemble.\n",
        "\n",
        "\n",
        "## Un découpage en work packages\n",
        "\n",
        "Ces ESSnets couvrent une variété de projets. Ceux-ci sont organisés par work packages, chacun avec ses propres objectifs.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Pour le WIN, on compte 4 work packages :\n",
        "    + [WP 1](https://ec.europa.eu/eurostat/cros/content/work-package-1-%E2%80%93-coordination-support-and-dissemination_en) : Coordination, support et dissémination\n",
        "    + [WP 2](https://ec.europa.eu/eurostat/cros/content/work-package-2-%E2%80%93-oja-and-obec-software_en) : Les projets `OJA` et `OBEC`\n",
        "    + [WP 3](https://ec.europa.eu/eurostat/cros/content/work-package-3-%E2%80%93-new-use-cases_en) : Nouveaux cas d'usage\n",
        "    + [WP 4](https://ec.europa.eu/eurostat/cros/content/work-package-4-%E2%80%93-methodology-and-quality_en) : Méthodologie et qualité\n",
        "\n",
        ". . .\n",
        "\n",
        "- L'INSEE est engagé dans les work packages 3 et 4.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Cas d'usage d'Eurostat {#04_02}\n",
        "\n",
        "## Le work package 2 du `WIN` {.smaller}\n",
        "\n",
        "- Il y a notamment deux gros projets de web scraping qui se sont poursuivis dans ces ESSnets :\n",
        "    + [Online Job Advertisements](https://ec.europa.eu/eurostat/cros/content/WPB_Online_job_vacancies_en) (`OJA`)\n",
        "        - Aussi appelé Online Job Vacancies (`OJV`)\n",
        "    + [Online-Based Enterprise Characteristics](https://ec.europa.eu/eurostat/cros/content/WPC_Enterprise_characteristics_en) (`OBEC`)\n",
        "\n",
        ". . .\n",
        "\n",
        "- Les deux projets faisaient également partie du '[Implementation Track](https://ec.europa.eu/eurostat/cros/content/implementation-track-0_en)' de l'ESSnet Big Data II.\n",
        "\n",
        ". . .\n",
        "\n",
        "::: {.callout-tip}\n",
        "## BREAL: Big data REference Architecture and Layers\n",
        "\n",
        "- Au sein du même track, on pourra aussi citer le projet '[Process and architecture](https://ec.europa.eu/eurostat/cros/content/WPF_Process_and_architecture_en)', qui a donné naissance au [BREAL](https://ec.europa.eu/eurostat/cros/content/wpf-deliverable-f2-breal-big-data-reference-architecture-and-layers-application-layer-and-information-layer-31-03-2021-finalpdf_en).\n",
        "\n",
        "- Cela représente désormais le work package 4 du WIN. Tous les rapports disponibles [ici](https://ec.europa.eu/eurostat/cros/content/wpf-milestones-and-deliverables_en).\n",
        ":::\n",
        "\n",
        "\n",
        "## Online Job Advertisements {.smaller}\n",
        "\n",
        "#### Contexte\n",
        "\n",
        "<br>\n",
        "\n",
        "- Besoin de statistiques sur les offres d'emploi les plus à jour possibles pour adapter les politiques d'emploi et d'éducation\n",
        "\n",
        ". . .\n",
        "\n",
        "- Les offres d'emploi étant de plus en plus en ligne, collecter ces données sur Internet devient particulièrement intéressant\n",
        "\n",
        ". . .\n",
        "\n",
        "- Les collectes de données traditionnelles sur les offres d'emploi sont assez peu efficaces\n",
        "\n",
        ". . .\n",
        "\n",
        "- Le web scraping estimé comme la solution la plus appropriée pour obtenir des données les plus complètes possibles\n",
        "\n",
        "\n",
        "## Online Job Advertisements\n",
        "\n",
        "#### Avantages du web scraping\n",
        "\n",
        "<br>\n",
        "\n",
        "- Possibilité de passer de données trimestrielles à des données journalières\n",
        "\n",
        ". . .\n",
        "\n",
        "- Sur les sites d'offres, celles-ci sont souvent déjà découpées par secteur, région, niveau d'éducation...\n",
        "\n",
        ". . .\n",
        "\n",
        "- Réduire le fardeau de réponse des entreprises\n",
        "\n",
        "\n",
        "## Online Job Advertisements\n",
        "\n",
        "#### Quelques challenges (1/2)\n",
        "\n",
        "- Bien définir le [__champ d'étude__]{.blue2}, par exemple restreindre aux secteurs avec une offre en grande partie en ligne\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Dédoublonner les offres__]{.blue2} présentes sur plusieurs plateformes (ex : les champs différant légèrement d'un site à l'autre à offre égale)\n",
        "\n",
        ". . .\n",
        "\n",
        "- Traiter à la fois des données structurées et non structurées (selon les sites)\n",
        "\n",
        ". . .\n",
        "\n",
        "- Savoir travailler avec les différents niveaux de détail ou unités de mesure qu'offre chaque site\n",
        "\n",
        "\n",
        "## Online Job Advertisements {.smaller}\n",
        "\n",
        "#### Quelques challenges (2/2)\n",
        "\n",
        "<br>\n",
        "\n",
        "- Gérer la qualité variable des données et les erreurs de scraping qui pourraient ressortir\n",
        "\n",
        ". . .\n",
        "\n",
        "- Bien respecter les règles en vigueur pour chaque site et pays au sujet du web scraping\n",
        "\n",
        ". . .\n",
        "\n",
        "- Gérer l'aspect temporel : \n",
        "    + Comparer les données du jour A à celles collectées la veille \n",
        "    + Évaluer la durée de validité des offres\n",
        "\n",
        ". . .\n",
        "\n",
        "- Gérer la représentativité des données `OJA` et le fait qu'il manque beaucoup d'offres non publiées en ligne\n",
        "\n",
        "\n",
        "## Online Job Advertisements\n",
        "\n",
        "#### Méthodes utilisées\n",
        "\n",
        "<br>\n",
        "\n",
        "- Scraping de nombreux sites d'offre d'emploi\n",
        "\n",
        ". . .\n",
        "\n",
        "- Méthodes poussées de NLP :\n",
        "    + Détection des langues\n",
        "    + Normalisations des textes\n",
        "    + Déduplications\n",
        "    + Classification par Machine Learning\n",
        "\n",
        "\n",
        "## Online Job Advertisements\n",
        "\n",
        "#### Conclusions\n",
        "\n",
        "<br>\n",
        "\n",
        "- En France, la [DARES](https://dares.travail-emploi.gouv.fr/) (Ministère du Travail) participe à ce travail.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Projet encore en cours, mais résultats très encourageants\n",
        "    + Les rapports publiés : [ici](https://ec.europa.eu/eurostat/cros/content/wpb-milestones-and-deliverables-0_en)\n",
        "    + Détails méthodologiques : [ici](https://ec.europa.eu/eurostat/cros/sites/default/files/ESSNet_II_WPB_OJV_Methodological_framework_V2.pdf)\n",
        "\n",
        "\n",
        "## [Online-Based Enterprise Characteristics](https://ec.europa.eu/eurostat/cros/content/WPC_Overview_en#Milestones_and_deliverables) {.smaller}\n",
        "\n",
        "#### Le principe\n",
        "\n",
        "<br>\n",
        "\n",
        "> \"The aim of WPC [Work Package C] is to use web scraping, text mining and inference techniques for collecting and processing enterprise information, in order to improve or update existing information, such as Internet presence, kind of activity, address information, ownership structure, etc., in the national business registers.\"\n",
        "\n",
        ". . .\n",
        "\n",
        "<br>\n",
        "\n",
        "Autrement dit, de nombreux sites d'entreprises sont scrapés afin d'en extraire des informations complémentaires aux enquêtes menées par les INS dans chaque pays.\n",
        "\n",
        "\n",
        "## Les différentes étapes d'OBEC\n",
        "\n",
        "#### 1- Politique de web scraping\n",
        "\n",
        "<br>\n",
        "\n",
        "- Le projet impliquant le scraping de nombreux sites dans plusieurs pays, il y a un fort besoin de transparence.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Outre la visibilité du projet, le `RGPD` ajoute un certain nombres de contraintes.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Une [politique sur l'usage du web scraping](https://ec.europa.eu/eurostat/cros/system/files/wpc_deliverable_c1_ess_web-scraping_policy_template_2019_07_15.pdf) pour le projet a donc été rédigée et diffusée.\n",
        "\n",
        "\n",
        "## Les différentes étapes d'OBEC\n",
        "\n",
        "#### 2- [Cadre méthodologique](https://ec.europa.eu/eurostat/cros/sites/default/files/WPC_Deliverable_C6_Reference_Methodological_Framework_v2.0.pdf)\n",
        "\n",
        "<br>\n",
        "\n",
        "- Cadrer le design du projet :\n",
        "    + Représentation de données, _process_ et méthodes...\n",
        "\n",
        ". . .\n",
        "\n",
        "- Cadrer la phase de déploiement :\n",
        "    + Infrastructure, étapes de data processing...\n",
        "\n",
        ". . .\n",
        "\n",
        "- Réfléchir au cycle de vie du projet en fonction du [GSBPM](https://unece.org/fileadmin/DAM/stats/documents/ece/ces/ge.58/2020/mtg2/MWW2020_GSBPM_Introduction.pdf)\n",
        "\n",
        "\n",
        "## Les différentes étapes d'OBEC\n",
        "\n",
        "#### 3- Expérimentations\n",
        "\n",
        "- Production de statistiques expérimentales en utilisant les méthodes d'`OBEC` :\n",
        "    + Collecte d'URL, présence sur les réseaux sociaux, activité en ligne, e-commerce...\n",
        "\n",
        ". . .\n",
        "\n",
        "- 7 pays volontaires, les rapports et résultats [ici](https://ec.europa.eu/eurostat/cros/content/wpc-experimental-statistics_en)\n",
        "    + Les résultats obtenus sont une vitrine d'`OBEC`...\n",
        "    + Mais ne peuvent pas encore être considérés comme des statistiques officielles\n",
        "\n",
        "\n",
        "## Les différentes étapes d'OBEC\n",
        "\n",
        "#### 4- Starting Kits\n",
        "\n",
        "<br>\n",
        "\n",
        "- Afin que chaque INS puisse mettre en application les méthodes mises en place lors du projet, un starting kit est disponible en open source.\n",
        "\n",
        "- Le [_deliverable_](https://ec.europa.eu/eurostat/cros/sites/default/files/WPC_Deliverable_C7_Starter_kit_for_NSIs_V.2.pdf) associé au starting kit\n",
        "\n",
        "- Le [code source](https://github.com/EnterpriseCharacteristicsESSnetBigData/StarterKit) sur `Github`\n",
        "\n",
        "\n",
        "## Les différentes étapes d'OBEC\n",
        "\n",
        "#### 5- Evaluation de la qualité des résultats\n",
        "\n",
        "- S'assurer de la qualité des résultats pour passer de la phase expérimentale à la mise en production par les INS\n",
        "\n",
        ". . .\n",
        "\n",
        "- Mise en place d'un [modèle](https://ec.europa.eu/eurostat/cros/sites/default/files/WPC_Deliverable_C5_Quality_template_for_statistical_outputs_2020_09_18_final.pdf) de suivi de la qualité des résultats\n",
        "    + Principalement issu de l'_\"[UNECE](https://unece.org/fr) Framework for the Quality of Big Data\"_\n",
        "\n",
        ". . .\n",
        "\n",
        "- Derniers documents publiés en Novembre 2020, travail poursuivi aujourd'hui avec le `WIN`\n",
        "\n",
        "\n",
        "## Quelques leçons tirées du scraping pour OBEC {.smaller}\n",
        "\n",
        "<table>\n",
        "   <tr>\n",
        "      <th>Problème rencontré</th>\n",
        "      <th>Réponse à adopter</th>\n",
        "   </tr>\n",
        "   <tr>\n",
        "      <td>Liste d'URL non à jour</td>\n",
        "      <td>Lancer un crawling pour vérifier validité des liens</td>\n",
        "   </tr>\n",
        "   <tr>\n",
        "      <td>Le robots.txt interdit le scraping de tout contenu</td>\n",
        "      <td>Notifier le site plus en amont de la collecte</td>\n",
        "   </tr>\n",
        "    <tr>\n",
        "      <td>Site temporairement indisponible</td>\n",
        "      <td>Essayer de scraper le site à des moments différents</td>\n",
        "   </tr>\n",
        "    <tr>\n",
        "      <td>Pas d'horodatage sur le site</td>\n",
        "      <td>Scraper le site régulièrement et comparer les sorties</td>\n",
        "   </tr>\n",
        "    <tr>\n",
        "      <td>Informations extraites du site insuffisantes</td>\n",
        "      <td>Le site a pu évoluer : revoir le code du scraping</td>\n",
        "   </tr>\n",
        "</table>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Web scraping dans un INS - Quelques interlocuteurs {#04_03}\n",
        "\n",
        "## Le [Web Intelligence Network](https://ec.europa.eu/eurostat/cros/WIN_en) {.smaller}\n",
        "\n",
        "<br>\n",
        "\n",
        "- Présents sur plusieurs media :\n",
        "    + [LinkedIn](https://www.linkedin.com/company/essnet-project-web-intelligence-network/)\n",
        "    + [Twitter](https://twitter.com/EssnetWin?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor)\n",
        "    + [Eventbrite](https://www.eventbrite.co.uk/o/essnet-web-intelligence-network-project-54944960133?utm_source=eventbrite&utm_medium=email&utm_campaign=event_reminder&utm_term=orgname)\n",
        "    + [Youtube](https://www.youtube.com/channel/UC5fUzazBu7d1Arl17LdC4zQ)\n",
        "\n",
        ". . .\n",
        "\n",
        "- Souhaitent également communiquer auprès d'INS hors Europe\n",
        "\n",
        ". . .\n",
        "\n",
        "- Un calendrier très complet d'événements, de webinaires...\n",
        "    + Dernier webinaire le 23/11 sur le work package 4 : \"BREAL et _user stories_\", qualité et méthodologie\n",
        "\n",
        "\n",
        "## Pour reprendre les mots du WIN ...\n",
        "\n",
        "<br>\n",
        "\n",
        "> The target audience for the WIH are organisations that produce national statistics and want to modernise the production of national statistics and are looking for:\n",
        ">\n",
        ">   * Exploring new and emerging data sources <br>\n",
        ">   * Building competences <br>\n",
        ">   * Building and strengthening collaborations <br>\n",
        ">   * Developing new frameworks <br>\n",
        ">   * Adopting new practices\n",
        "\n",
        "\n",
        "## Les webinaires du WIN des prochains mois {.smaller}\n",
        "\n",
        "<br>\n",
        "\n",
        "- [__Début 2023__]{.blue2} :\n",
        "    + \"Web Scraped Data to Enhance the Quality of the Statistical Business Register\"\n",
        "    + \"Method of Processing and Analysing Web Scraped Tourism Data\"\n",
        "    + \"Web Intelligence in Practice. How to use content form the web for enterprise statistics?\"\n",
        "\n",
        ". . .\n",
        "\n",
        "- [__Mi 2023__]{.blue2} :\n",
        "    + \"Web Scraping of Real Estate Portals\"\n",
        "\n",
        ". . .\n",
        "\n",
        "- Davantage d'informations à venir pour la suite\n",
        "\n",
        "\n",
        "## L'INS du Royaume-Uni : l'[ONS](https://www.ons.gov.uk/)\n",
        "\n",
        "<br>\n",
        "\n",
        "- Un [blog](https://datasciencecampus.ons.gov.uk/) consacré à la data science alimenté régulièrement\n",
        "\n",
        ". . .\n",
        "\n",
        "- Une politique de web scraping très mature, disponible [ici](https://www.ons.gov.uk/aboutus/transparencyandgovernance/datastrategy/datapolicies/webscrapingpolicy) et [ici](https://www.ons.gov.uk/file?uri=/aboutus/transparencyandgovernance/datastrategy/datapolicies/webscrapingpolicy/webscrapingpolicy.pdf)\n",
        "    - Ne pas hésiter à lire leur liste des bonnes pratiques, très bien faite\n",
        "\n",
        ". . .\n",
        "\n",
        "- Prompts à multiplier les [partenariats](https://datasciencecampus.ons.gov.uk/partnerships/)\n",
        "\n",
        "\n",
        "## Quid de recourir à des acteurs privés spécialisés ?\n",
        "\n",
        "- Il existe de nombreuses entreprises proposant des services de scraping.\n",
        "\n",
        ". . .\n",
        "\n",
        "- En revanche, aucune garantie que les _guidelines_ présentées soient appliquées.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Possibles problématiques de transparence sur la collecte.\n",
        "\n",
        ". . .\n",
        "\n",
        "Ce n'est donc pas une recommandation. Ce n'est ni une pratique à l'INSEE ni à Eurostat.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# V. Conclusion {#index_05}\n",
        "\n",
        "## Le mot de la fin\n",
        "\n",
        "- Le web scraping est une nouvelle source de données très prometteuse.\n",
        "    - Les cas d'usage sont nombreux, y compris pour les INS.\n",
        "\n",
        ". . .\n",
        "\n",
        "- En revanche attention, même à des fins statistiques, tout n'est pas permis.\n",
        "    - Bien respecter les bonnes pratiques.\n",
        "\n",
        ". . .\n",
        "\n",
        "- Un réseau d'interlocuteurs à disposition\n",
        "    - A travers le `WIN` ou entre INS\n",
        "\n",
        "\n",
        "## Remerciements aux contributeurs\n",
        "\n",
        "<br>\n",
        "\n",
        "- [Lino Galiana](https://github.com/linogaliana/), INSEE\n",
        "- [Romain Lesur](https://github.com/RLesur/), INSEE\n",
        "- [Romain Avouac](https://github.com/avouacr/), INSEE\n",
        "\n",
        ". . .\n",
        "\n",
        "Le code source de la formation sur `Github` accessible [ici](https://github.com/antoine-palazz/webscraping_formation)\n",
        "\n",
        ". . .\n",
        "\n",
        "<br>\n",
        "\n",
        "[Retour au début](#index)\n",
        "\n",
        "\n",
        "# Merci pour votre attention !\n",
        "\n",
        "<br>\n",
        "\n",
        "Des questions ?\n"
      ],
      "id": "e8d1b3fe"
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
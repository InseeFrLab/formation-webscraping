## Le webscraping, est-ce légal ?

- Le webscraping en lui-même n'est pas une pratique illégale, mais l'utilisation faite des données scrapées peut être soumise à règlementation.

- Ainsi, scraper un site pour conserver les données sur son ordinateur est légal.

- En revanche, diffuser ou commercialiser ces données ou un quelconque travail réutilisant ces données n'est pas sans conséquence.


## Une frontière floue

- Les législations spécifiques au webscraping sont peu nombreuses. En revanche, la réutilisation des données est encadrée, par exemple par le code de la propriété intellectuelle ou en Europe par le RGPD.

- Les [cas portés en justice](https://devm.io/law-net-culture/data-scraping-cases-165385) ont des dénouements parfois différents les uns les autres, notamment d'un pays à l'autre, montrant bien qu'il s'agit là d'une zone parfois grise.


## Les principales règlementations autour du webscraping - En France

- [L'article L342-1 du code de la propriété intellectuelle](https://www.legifrance.gouv.fr/codes/article_lc/LEGIARTI000006279247), ici assimilé au droit d'auteur

- L'[article 323-3 du Code Pénal](https://www.legifrance.gouv.fr/codes/article_lc/LEGIARTI000030939448) : "Le fait d'introduire frauduleusement des données dans un système de traitement automatisé, d'extraire, de détenir, de reproduire, de transmettre, de supprimer ou de modifier frauduleusement les données qu'il contient est puni de cinq ans d'emprisonnement et de 150 000 € d'amende"

- En termes de droit de la concurrence, on pourra aussi parler de concurrence déloyale avec l'[article L121-1 du Code de la Consommation](https://www.legifrance.gouv.fr/codes/article_lc/LEGIARTI000032227301/)


## Les principales règlementations autour du webscraping - En Europe

- Le droit [sui generis](https://fr.wikipedia.org/wiki/Sui_generis), à l'échelle européenne, protégeant les bases de données ayant nécessité un "investissement substantiel"

- Certaines directives relatives à la protection des bases de données en Europe.
    - Ex : [Directive 96/9/CE du Parlement Européen et du conseil](https://eur-lex.europa.eu/LexUriServ/LexUriServ.do?uri=CELEX:31996L0009:fr:HTML)


## Les principales règlementations autour du webscraping - Encore d'autres

- Les jurisprudences issues des procès d'entreprises liés au webscraping

- Les mentions légales, conditions d'utilisation et autres consignes des sites concernés

- Aux États-Unis, plusieurs textes peuvent s'appliquer : le California [Consumer Privacy Act](https://oag.ca.gov/privacy/ccpa), le [Computer Fraud and Abuse Act](https://www.nacdl.org/Landing/ComputerFraudandAbuseAct), ...


## Outre les protections légales, les sites se protègent eux-mêmes

- Afin d'éviter la réutilisation de leur contenu par des concurrents et lutter contre l'espionnage

- Afin de bloquer les bots qui occupent une partie significative du trafic, ralentissant ainsi l'accès au site, et qui peuvent s'assimiler à une [attaque DDoS](https://fr.wikipedia.org/wiki/Attaque_par_d%C3%A9ni_de_service)


## Les méthodes mises en place pour se protéger du scraping (1/2)

- Mettre en place des conditions d'utilisation contraignantes et instructions explicites pour se protéger d'un point de vue légal

- Repérer les adresses IP suspectes et bloquer leur accès au site, temporairement ou de façon permanente

- Identifier les bots et leur afficher un contenu différent des utilisateurs classiques, pour par exemple renvoyer de fausses données


## Les méthodes mises en place pour se protéger du scraping (2/2)

- Modifier régulièrement le format HTML du contenu pour empêcher l'automatisation du scraping par autrui

- Créer des pages "Honeypot" qu'un humain ne visiterait jamais pour identifier puis bloquer des bots

- Utiliser des CAPTCHAs lorsqu'une activité suspecte est repérée


## Les limites du webscraping

- La qualité des données obtenues par scraping n'est pas toujours au rendez-vous.

- Les risques légaux sont existants, et plus généralement cela peut nuire à l'image d'un INS.

- Il vaut mieux favoriser des relations de confiance avec les sites concernés.


## Dans ces conditions, quand envisager le webscraping ?

La politique de l'INSEE est de garder le webscraping comme dernière option. Les premières étapes recommandées sont d'abord de :

- Demander directement aux sites concernés l'accès à leurs données et nouer d'éventuels partenariats, par exemple avec une contrepartie
- Chercher s'il existe une API du site permettant d'accéder aux données
- Chercher des alternatives, comme accéder à des données similaires via un moyen moins contraignant


## Pour un scraping "éthique"

- Le webscraping reste malgré tout une source de données très efficiente dans le cas où aucune meilleure alternative ne se présente. Il ne faut donc pas s'en priver.

- Cependant, il existe des moyens de scraper de façon "éthique" et en minimisant la charge sur le site scrapé.

- Cela passe par exemple par demander la permission aux sites à scraper.


## Les guidelines du Système Statistique Européen : transparence

- Rendre publique la liste des collectes de données par scraping de l'INS, autrement dit être transparent

- Si l'impact sur site va être important (par exemple un scraping fait très fréquemment), informer spécifiquement le site concerné

- S'identifier auprès du site lors de l'opération de scraping (sauf cas particuliers)


## Les guidelines du Système Statistique Européen : minimiser l'impact

- Toujours chercher à minimiser l'impact sur les serveurs du site scrapé, notamment en limitant les requêtes effectuées au minimum requis

- Privilégier les heures creuses du site pour les opérations de scraping

- Étaler les requêtes en laissant un temps de 'pause' entrre chaque requête sur site


## Les guidelines du Système Statistique Européen : confiance

- Favoriser les échanges avec les propriétaires des sites : partenariats, échanges de données, requêtes d'API, ...

- Se plier aux conditions d'utilisation des sites concernés et aux règlementations de la zone concernée

- Manipuler de façon sécurisée les données scrapées


## Ce qu'il ne faut pas faire

xxx